{
    "name": "rdkafka",
    "version": "0.37.0",
    "description": "ALLOW: Positive community sentiment",
    "repository": "",
    "keywords": [],
    "categories": [],
    "readme": {
        "raw_markdown": "[](https://docs.rs/rdkafka/latest/rdkafka/all.html \"show sidebar\")\n# Crate rdkafkaCopy item path\n[Settings](https://docs.rs/rdkafka/latest/settings.html)\n[Help](https://docs.rs/rdkafka/latest/help.html)\nSummary[Source](https://docs.rs/rdkafka/latest/src/rdkafka/lib.rs.html#1-297)\nExpand description\nA fully asynchronous, [futures](https://github.com/rust-lang/futures-rs)-enabled [Apache Kafka](https://kafka.apache.org) client library for Rust based on [librdkafka](https://github.com/edenhill/librdkafka).\n### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#the-library)The library\n`rust-rdkafka` provides a safe Rust interface to librdkafka. This version is compatible with librdkafka v1.9.2+.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#documentation)Documentation\n  * [Current master branch](https://fede1024.github.io/rust-rdkafka/)\n  * [Latest release](https://docs.rs/rdkafka/)\n  * [Changelog](https://github.com/fede1024/rust-rdkafka/blob/master/changelog.md)\n\n\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#features)Features\nThe main features provided at the moment are:\n  * Support for all Kafka versions since 0.8.x. For more information about broker compatibility options, check the [librdkafka documentation](https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#broker-version-compatibility).\n  * Consume from single or multiple topics.\n  * Automatic consumer rebalancing.\n  * Customizable rebalance, with pre and post rebalance callbacks.\n  * Synchronous or asynchronous message production.\n  * Customizable offset commit.\n  * Create and delete topics and add and edit partitions.\n  * Alter broker and topic configurations.\n  * Access to cluster metadata (list of topic-partitions, replicas, active brokers etc).\n  * Access to group metadata (list groups, list members of groups, hostnames, etc.).\n  * Access to producer and consumer metrics, errors and callbacks.\n  * Exactly-once semantics (EOS) via idempotent and transactional producers and read-committed consumers.\n\n\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#one-million-messages-per-second)One million messages per second\n`rust-rdkafka` is designed to be easy and safe to use thanks to the abstraction layer written in Rust, while at the same time being extremely fast thanks to the librdkafka C library.\nHere are some benchmark results using the [`BaseProducer`](https://docs.rs/rdkafka/*/rdkafka/producer/base_producer/struct.BaseProducer.html), sending data to a single Kafka 0.11 process running in localhost (default configuration, 3 partitions). Hardware: Dell laptop, with Intel Core i7-4712HQ @ 2.30GHz.\n  * Scenario: produce 5 million messages, 10 bytes each, wait for all of them to be acked\n    * 1045413 messages/s, 9.970 MB/s (average over 5 runs)\n  * Scenario: produce 100000 messages, 10 KB each, wait for all of them to be acked\n    * 24623 messages/s, 234.826 MB/s (average over 5 runs)\n\n\nFor more numbers, check out the [kafka-benchmark](https://github.com/fede1024/kafka-benchmark) project.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#client-types)Client types\n`rust-rdkafka` provides low level and high level consumers and producers.\nLow level:\n  * [`BaseConsumer`](https://docs.rs/rdkafka/*/rdkafka/consumer/base_consumer/struct.BaseConsumer.html): a simple wrapper around the librdkafka consumer. It must be periodically `poll()`ed in order to execute callbacks, rebalances and to receive messages.\n  * [`BaseProducer`](https://docs.rs/rdkafka/*/rdkafka/producer/base_producer/struct.BaseProducer.html): a simple wrapper around the librdkafka producer. As in the consumer case, the user must call `poll()` periodically to execute delivery callbacks.\n  * [`ThreadedProducer`](https://docs.rs/rdkafka/*/rdkafka/producer/base_producer/struct.ThreadedProducer.html): a `BaseProducer` with a separate thread dedicated to polling the producer.\n\n\nHigh level:\n  * [`StreamConsumer`](https://docs.rs/rdkafka/*/rdkafka/consumer/stream_consumer/struct.StreamConsumer.html): a [`Stream`](https://docs.rs/futures/*/futures/stream/trait.Stream.html) of messages that takes care of polling the consumer automatically.\n  * [`FutureProducer`](https://docs.rs/rdkafka/*/rdkafka/producer/future_producer/struct.FutureProducer.html): a [`Future`](https://doc.rust-lang.org/stable/std/future/trait.Future.html) that will be completed once the message is delivered to Kafka (or failed).\n\n\nFor more information about consumers and producers, refer to their module-level documentation.\n_Warning_ : the library is under active development and the APIs are likely to change.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#asynchronous-data-processing-with-tokio)Asynchronous data processing with Tokio\n[Tokio](https://tokio.rs/) is a platform for fast processing of asynchronous events in Rust. The interfaces exposed by the [`StreamConsumer`](https://docs.rs/rdkafka/*/rdkafka/consumer/stream_consumer/struct.StreamConsumer.html) and the [`FutureProducer`](https://docs.rs/rdkafka/*/rdkafka/producer/future_producer/struct.FutureProducer.html) allow rust-rdkafka users to easily integrate Kafka consumers and producers within the Tokio platform, and write asynchronous message processing code. Note that rust-rdkafka can be used without Tokio.\nTo see rust-rdkafka in action with Tokio, check out the [asynchronous processing example](https://github.com/fede1024/rust-rdkafka/blob/master/examples/asynchronous_processing.rs) in the examples folder.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#at-least-once-delivery)At-least-once delivery\nAt-least-once delivery semantics are common in many streaming applications: every message is guaranteed to be processed at least once; in case of temporary failure, the message can be re-processed and/or re-delivered, but no message will be lost.\nIn order to implement at-least-once delivery the stream processing application has to carefully commit the offset only once the message has been processed. Committing the offset too early, instead, might cause message loss, since upon recovery the consumer will start from the next message, skipping the one where the failure occurred.\nTo see how to implement at-least-once delivery with `rdkafka`, check out the [at-least-once delivery example](https://github.com/fede1024/rust-rdkafka/blob/master/examples/at_least_once.rs) in the examples folder. To know more about delivery semantics, check the [message delivery semantics](https://kafka.apache.org/0101/documentation.html#semantics) chapter in the Kafka documentation.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#exactly-once-semantics)Exactly-once semantics\nExactly-once semantics (EOS) can be achieved using transactional producers, which allow produced records and consumer offsets to be committed or aborted atomically. Consumers that set their `isolation.level` to `read_committed` will only observe committed messages.\nEOS is useful in read-process-write scenarios that require messages to be processed exactly once.\nTo learn more about using transactions in rust-rdkafka, see the [Transactions](https://docs.rs/rdkafka/latest/rdkafka/producer-transactions) section of the producer documentation.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#users)Users\nHere are some of the projects using rust-rdkafka:\n  * [timely-dataflow](https://github.com/frankmcsherry/timely-dataflow): a distributed data-parallel compute engine. See also the [blog post](https://github.com/frankmcsherry/blog/blob/master/posts/2017-11-08.md) announcing its Kafka integration.\n  * [kafka-view](https://github.com/fede1024/kafka-view): a web interface for Kafka clusters.\n  * [kafka-benchmark](https://github.com/fede1024/kafka-benchmark): a high performance benchmarking tool for Kafka.\n  * [callysto](https://github.com/vertexclique/callysto): Stream processing framework in Rust.\n  * [bytewax](https://github.com/bytewax/bytewax): Python stream processing framework using Timely Dataflow.\n\n\n_If you are using rust-rdkafka, please let us know!_\n### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#installation)Installation\nAdd this to your `Cargo.toml`:\n```\n[dependencies]\nrdkafka = { version = \"0.25\", features = [\"cmake-build\"] }\n```\n\nThis crate will compile librdkafka from sources and link it statically to your executable. To compile librdkafka you\u2019ll need:\n  * the GNU toolchain\n  * GNU `make`\n  * `pthreads`\n  * `zlib`: optional, but included by default (feature: `libz`)\n  * `cmake`: optional, _not_ included by default (feature: `cmake-build`)\n  * `libssl-dev`: optional, _not_ included by default (feature: `ssl`)\n  * `libsasl2-dev`: optional, _not_ included by default (feature: `gssapi`)\n  * `libzstd-dev`: optional, _not_ included by default (feature: `zstd-pkg-config`)\n\n\nNote that using the CMake build system, via the `cmake-build` feature, is encouraged if you can take the dependency on CMake.\nBy default a submodule with the librdkafka sources pinned to a specific commit will be used to compile and statically link the library. The `dynamic-linking` feature can be used to instead dynamically link rdkafka to the system\u2019s version of librdkafka. Example:\n```\n[dependencies]\nrdkafka = { version = \"0.25\", features = [\"dynamic-linking\"] }\n```\n\nFor a full listing of features, consult the [rdkafka-sys crate\u2019s documentation](https://github.com/fede1024/rust-rdkafka/tree/master/rdkafka-sys/README.md#features). All of rdkafka-sys features are re-exported as rdkafka features.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#minimum-supported-rust-version-msrv)Minimum supported Rust version (MSRV)\nThe current minimum supported Rust version (MSRV) is 1.70.0. Note that bumping the MSRV is not considered a breaking change. Any release of rust-rdkafka may bump the MSRV.\n#### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#asynchronous-runtimes)Asynchronous runtimes\nSome features of the [`StreamConsumer`](https://docs.rs/rdkafka/*/rdkafka/consumer/stream_consumer/struct.StreamConsumer.html) and [`FutureProducer`](https://docs.rs/rdkafka/*/rdkafka/producer/future_producer/struct.FutureProducer.html) depend on Tokio, which can be a heavyweight dependency for users who only intend to use the low-level consumers and producers. The Tokio integration is enabled by default, but can be disabled by turning off default features:\n```\n[dependencies]\nrdkafka = { version = \"0.25\", default-features = false }\n```\n\nIf you would like to use an asynchronous runtime besides Tokio, you can integrate it with rust-rdkafka by providing a shim that implements the [`AsyncRuntime`](https://docs.rs/rdkafka/*/rdkafka/util/trait.AsyncRuntime.html) trait. See the following examples for details:\n  * [smol](https://github.com/fede1024/rust-rdkafka/blob/master/examples/runtime_smol.rs)\n  * [async-std](https://github.com/fede1024/rust-rdkafka/blob/master/examples/runtime_async_std.rs)\n\n\n### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#examples)Examples\nYou can find examples in the [`examples`](https://github.com/fede1024/rust-rdkafka/blob/master/examples/) folder. To run them:\n```\ncargo run --example <example_name> -- <example_args>\n```\n\n### [\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#debugging)Debugging\nrust-rdkafka uses the [`log`](https://docs.rs/log) crate to handle logging. Optionally, enable the `tracing` feature to emit [`tracing`](https://docs.rs/tracing) events as opposed to [`log`](https://docs.rs/log) records.\nIn test and examples, rust-rdkafka uses the [`env_logger`](https://docs.rs/env_logger) crate to format logs. In those contexts, logging can be enabled using the `RUST_LOG` environment variable, for example:\n```\nRUST_LOG=\"librdkafka=trace,rdkafka::client=debug\" cargo test\n```\n\nThis will configure the logging level of librdkafka to trace, and the level of the client module of the Rust client to debug. To actually receive logs from librdkafka, you also have to set the `debug` option in the producer or consumer configuration (see librdkafka [configuration](https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md)).\nTo enable debugging in your project, make sure you initialize the logger with `env_logger::init()`, or the equivalent for any `log`-compatible logging framework.\n## Re-exports[\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#reexports)\n\n`pub use crate::client::ClientContext[](https://docs.rs/rdkafka/latest/rdkafka/client/trait.ClientContext.html \"trait rdkafka::client::ClientContext\");`\n\n\n`pub use crate::config::ClientConfig[](https://docs.rs/rdkafka/latest/rdkafka/config/struct.ClientConfig.html \"struct rdkafka::config::ClientConfig\");`\n\n\n`pub use crate::message::Message[](https://docs.rs/rdkafka/latest/rdkafka/message/trait.Message.html \"trait rdkafka::message::Message\");`\n\n\n`pub use crate::message::Timestamp[](https://docs.rs/rdkafka/latest/rdkafka/message/enum.Timestamp.html \"enum rdkafka::message::Timestamp\");`\n\n\n`pub use crate::statistics::Statistics[](https://docs.rs/rdkafka/latest/rdkafka/statistics/struct.Statistics.html \"struct rdkafka::statistics::Statistics\");`\n\n\n`pub use crate::topic_partition_list::Offset[](https://docs.rs/rdkafka/latest/rdkafka/topic_partition_list/enum.Offset.html \"enum rdkafka::topic_partition_list::Offset\");`\n\n\n`pub use crate::topic_partition_list::TopicPartitionList[](https://docs.rs/rdkafka/latest/rdkafka/topic_partition_list/struct.TopicPartitionList.html \"struct rdkafka::topic_partition_list::TopicPartitionList\");`\n\n\n`pub use crate::util::IntoOpaque[](https://docs.rs/rdkafka/latest/rdkafka/util/trait.IntoOpaque.html \"trait rdkafka::util::IntoOpaque\");`\n\n## Modules[\u00a7](https://docs.rs/rdkafka/latest/rdkafka/#modules)\n\n[admin](https://docs.rs/rdkafka/latest/rdkafka/admin/index.html \"mod rdkafka::admin\")\n    Admin client.\n\n[bindings](https://docs.rs/rdkafka/latest/rdkafka/bindings/index.html \"mod rdkafka::bindings\")\n    FFI bindings.\n\n[client](https://docs.rs/rdkafka/latest/rdkafka/client/index.html \"mod rdkafka::client\")\n    Common client functionality.\n\n[config](https://docs.rs/rdkafka/latest/rdkafka/config/index.html \"mod rdkafka::config\")\n    Producer and consumer configuration.\n\n[consumer](https://docs.rs/rdkafka/latest/rdkafka/consumer/index.html \"mod rdkafka::consumer\")\n    Kafka consumers.\n\n[error](https://docs.rs/rdkafka/latest/rdkafka/error/index.html \"mod rdkafka::error\")\n    Error manipulations.\n\n[groups](https://docs.rs/rdkafka/latest/rdkafka/groups/index.html \"mod rdkafka::groups\")\n    Group membership API.\n\n[helpers](https://docs.rs/rdkafka/latest/rdkafka/helpers/index.html \"mod rdkafka::helpers\")\n    Utility functions.\n\n[message](https://docs.rs/rdkafka/latest/rdkafka/message/index.html \"mod rdkafka::message\")\n    Store and manipulate Kafka messages.\n\n[metadata](https://docs.rs/rdkafka/latest/rdkafka/metadata/index.html \"mod rdkafka::metadata\")\n    Cluster metadata.\n\n[mocking](https://docs.rs/rdkafka/latest/rdkafka/mocking/index.html \"mod rdkafka::mocking\")\n    Mocking functionality\n\n[producer](https://docs.rs/rdkafka/latest/rdkafka/producer/index.html \"mod rdkafka::producer\")\n    Kafka producers.\n\n[statistics](https://docs.rs/rdkafka/latest/rdkafka/statistics/index.html \"mod rdkafka::statistics\")\n    Client and broker statistics.\n\n[topic_partition_list](https://docs.rs/rdkafka/latest/rdkafka/topic_partition_list/index.html \"mod rdkafka::topic_partition_list\")\n    Data structures representing topic, partitions and offsets.\n\n[types](https://docs.rs/rdkafka/latest/rdkafka/types/index.html \"mod rdkafka::types\")\n    Aliases for types defined in the auto-generated bindings.\n\n[util](https://docs.rs/rdkafka/latest/rdkafka/util/index.html \"mod rdkafka::util\")\n    Utility functions and types.\n",
        "markdown_with_citations": "[](https://docs.rs/rdkafka/latest/rdkafka/all.html \"show sidebar\")\n# Crate rdkafkaCopy item path\nSettings\u27e81\u27e9\nHelp\u27e82\u27e9\nSummarySource\u27e83\u27e9\nExpand description\nA fully asynchronous, futures\u27e84\u27e9-enabled Apache Kafka\u27e85\u27e9 client library for Rust based on librdkafka\u27e86\u27e9.\n### \u00a7\u27e87\u27e9The library\n`rust-rdkafka` provides a safe Rust interface to librdkafka. This version is compatible with librdkafka v1.9.2+.\n#### \u00a7\u27e88\u27e9Documentation\n  * Current master branch\u27e89\u27e9\n  * Latest release\u27e810\u27e9\n  * Changelog\u27e811\u27e9\n\n\n#### \u00a7\u27e812\u27e9Features\nThe main features provided at the moment are:\n  * Support for all Kafka versions since 0.8.x. For more information about broker compatibility options, check the librdkafka documentation\u27e813\u27e9.\n  * Consume from single or multiple topics.\n  * Automatic consumer rebalancing.\n  * Customizable rebalance, with pre and post rebalance callbacks.\n  * Synchronous or asynchronous message production.\n  * Customizable offset commit.\n  * Create and delete topics and add and edit partitions.\n  * Alter broker and topic configurations.\n  * Access to cluster metadata (list of topic-partitions, replicas, active brokers etc).\n  * Access to group metadata (list groups, list members of groups, hostnames, etc.).\n  * Access to producer and consumer metrics, errors and callbacks.\n  * Exactly-once semantics (EOS) via idempotent and transactional producers and read-committed consumers.\n\n\n#### \u00a7\u27e814\u27e9One million messages per second\n`rust-rdkafka` is designed to be easy and safe to use thanks to the abstraction layer written in Rust, while at the same time being extremely fast thanks to the librdkafka C library.\nHere are some benchmark results using the `BaseProducer`\u27e815\u27e9, sending data to a single Kafka 0.11 process running in localhost (default configuration, 3 partitions). Hardware: Dell laptop, with Intel Core i7-4712HQ @ 2.30GHz.\n  * Scenario: produce 5 million messages, 10 bytes each, wait for all of them to be acked\n    * 1045413 messages/s, 9.970 MB/s (average over 5 runs)\n  * Scenario: produce 100000 messages, 10 KB each, wait for all of them to be acked\n    * 24623 messages/s, 234.826 MB/s (average over 5 runs)\n\n\nFor more numbers, check out the kafka-benchmark\u27e816\u27e9 project.\n#### \u00a7\u27e817\u27e9Client types\n`rust-rdkafka` provides low level and high level consumers and producers.\nLow level:\n  * `BaseConsumer`\u27e818\u27e9: a simple wrapper around the librdkafka consumer. It must be periodically `poll()`ed in order to execute callbacks, rebalances and to receive messages.\n  * `BaseProducer`\u27e815\u27e9: a simple wrapper around the librdkafka producer. As in the consumer case, the user must call `poll()` periodically to execute delivery callbacks.\n  * `ThreadedProducer`\u27e819\u27e9: a `BaseProducer` with a separate thread dedicated to polling the producer.\n\n\nHigh level:\n  * `StreamConsumer`\u27e820\u27e9: a `Stream`\u27e821\u27e9 of messages that takes care of polling the consumer automatically.\n  * `FutureProducer`\u27e822\u27e9: a `Future`\u27e823\u27e9 that will be completed once the message is delivered to Kafka (or failed).\n\n\nFor more information about consumers and producers, refer to their module-level documentation.\n_Warning_ : the library is under active development and the APIs are likely to change.\n#### \u00a7\u27e824\u27e9Asynchronous data processing with Tokio\nTokio\u27e825\u27e9 is a platform for fast processing of asynchronous events in Rust. The interfaces exposed by the `StreamConsumer`\u27e820\u27e9 and the `FutureProducer`\u27e822\u27e9 allow rust-rdkafka users to easily integrate Kafka consumers and producers within the Tokio platform, and write asynchronous message processing code. Note that rust-rdkafka can be used without Tokio.\nTo see rust-rdkafka in action with Tokio, check out the asynchronous processing example\u27e826\u27e9 in the examples folder.\n#### \u00a7\u27e827\u27e9At-least-once delivery\nAt-least-once delivery semantics are common in many streaming applications: every message is guaranteed to be processed at least once; in case of temporary failure, the message can be re-processed and/or re-delivered, but no message will be lost.\nIn order to implement at-least-once delivery the stream processing application has to carefully commit the offset only once the message has been processed. Committing the offset too early, instead, might cause message loss, since upon recovery the consumer will start from the next message, skipping the one where the failure occurred.\nTo see how to implement at-least-once delivery with `rdkafka`, check out the at-least-once delivery example\u27e828\u27e9 in the examples folder. To know more about delivery semantics, check the message delivery semantics\u27e829\u27e9 chapter in the Kafka documentation.\n#### \u00a7\u27e830\u27e9Exactly-once semantics\nExactly-once semantics (EOS) can be achieved using transactional producers, which allow produced records and consumer offsets to be committed or aborted atomically. Consumers that set their `isolation.level` to `read_committed` will only observe committed messages.\nEOS is useful in read-process-write scenarios that require messages to be processed exactly once.\nTo learn more about using transactions in rust-rdkafka, see the Transactions\u27e831\u27e9 section of the producer documentation.\n#### \u00a7\u27e832\u27e9Users\nHere are some of the projects using rust-rdkafka:\n  * timely-dataflow\u27e833\u27e9: a distributed data-parallel compute engine. See also the blog post\u27e834\u27e9 announcing its Kafka integration.\n  * kafka-view\u27e835\u27e9: a web interface for Kafka clusters.\n  * kafka-benchmark\u27e816\u27e9: a high performance benchmarking tool for Kafka.\n  * callysto\u27e836\u27e9: Stream processing framework in Rust.\n  * bytewax\u27e837\u27e9: Python stream processing framework using Timely Dataflow.\n\n\n_If you are using rust-rdkafka, please let us know!_\n### \u00a7\u27e838\u27e9Installation\nAdd this to your `Cargo.toml`:\n```\n[dependencies]\nrdkafka = { version = \"0.25\", features = [\"cmake-build\"] }\n```\n\nThis crate will compile librdkafka from sources and link it statically to your executable. To compile librdkafka you\u2019ll need:\n  * the GNU toolchain\n  * GNU `make`\n  * `pthreads`\n  * `zlib`: optional, but included by default (feature: `libz`)\n  * `cmake`: optional, _not_ included by default (feature: `cmake-build`)\n  * `libssl-dev`: optional, _not_ included by default (feature: `ssl`)\n  * `libsasl2-dev`: optional, _not_ included by default (feature: `gssapi`)\n  * `libzstd-dev`: optional, _not_ included by default (feature: `zstd-pkg-config`)\n\n\nNote that using the CMake build system, via the `cmake-build` feature, is encouraged if you can take the dependency on CMake.\nBy default a submodule with the librdkafka sources pinned to a specific commit will be used to compile and statically link the library. The `dynamic-linking` feature can be used to instead dynamically link rdkafka to the system\u2019s version of librdkafka. Example:\n```\n[dependencies]\nrdkafka = { version = \"0.25\", features = [\"dynamic-linking\"] }\n```\n\nFor a full listing of features, consult the rdkafka-sys crate\u2019s documentation\u27e839\u27e9. All of rdkafka-sys features are re-exported as rdkafka features.\n#### \u00a7\u27e840\u27e9Minimum supported Rust version (MSRV)\nThe current minimum supported Rust version (MSRV) is 1.70.0. Note that bumping the MSRV is not considered a breaking change. Any release of rust-rdkafka may bump the MSRV.\n#### \u00a7\u27e841\u27e9Asynchronous runtimes\nSome features of the `StreamConsumer`\u27e820\u27e9 and `FutureProducer`\u27e822\u27e9 depend on Tokio, which can be a heavyweight dependency for users who only intend to use the low-level consumers and producers. The Tokio integration is enabled by default, but can be disabled by turning off default features:\n```\n[dependencies]\nrdkafka = { version = \"0.25\", default-features = false }\n```\n\nIf you would like to use an asynchronous runtime besides Tokio, you can integrate it with rust-rdkafka by providing a shim that implements the `AsyncRuntime`\u27e842\u27e9 trait. See the following examples for details:\n  * smol\u27e843\u27e9\n  * async-std\u27e844\u27e9\n\n\n### \u00a7\u27e845\u27e9Examples\nYou can find examples in the `examples`\u27e846\u27e9 folder. To run them:\n```\ncargo run --example <example_name> -- <example_args>\n```\n\n### \u00a7\u27e847\u27e9Debugging\nrust-rdkafka uses the `log`\u27e848\u27e9 crate to handle logging. Optionally, enable the `tracing` feature to emit `tracing`\u27e849\u27e9 events as opposed to `log`\u27e848\u27e9 records.\nIn test and examples, rust-rdkafka uses the `env_logger`\u27e850\u27e9 crate to format logs. In those contexts, logging can be enabled using the `RUST_LOG` environment variable, for example:\n```\nRUST_LOG=\"librdkafka=trace,rdkafka::client=debug\" cargo test\n```\n\nThis will configure the logging level of librdkafka to trace, and the level of the client module of the Rust client to debug. To actually receive logs from librdkafka, you also have to set the `debug` option in the producer or consumer configuration (see librdkafka configuration\u27e851\u27e9).\nTo enable debugging in your project, make sure you initialize the logger with `env_logger::init()`, or the equivalent for any `log`-compatible logging framework.\n## Re-exports\u00a7\u27e852\u27e9\n\n`pub use crate::client::ClientContext[](https://docs.rs/rdkafka/latest/rdkafka/client/trait.ClientContext.html \"trait rdkafka::client::ClientContext\");`\n\n\n`pub use crate::config::ClientConfig[](https://docs.rs/rdkafka/latest/rdkafka/config/struct.ClientConfig.html \"struct rdkafka::config::ClientConfig\");`\n\n\n`pub use crate::message::Message[](https://docs.rs/rdkafka/latest/rdkafka/message/trait.Message.html \"trait rdkafka::message::Message\");`\n\n\n`pub use crate::message::Timestamp[](https://docs.rs/rdkafka/latest/rdkafka/message/enum.Timestamp.html \"enum rdkafka::message::Timestamp\");`\n\n\n`pub use crate::statistics::Statistics[](https://docs.rs/rdkafka/latest/rdkafka/statistics/struct.Statistics.html \"struct rdkafka::statistics::Statistics\");`\n\n\n`pub use crate::topic_partition_list::Offset[](https://docs.rs/rdkafka/latest/rdkafka/topic_partition_list/enum.Offset.html \"enum rdkafka::topic_partition_list::Offset\");`\n\n\n`pub use crate::topic_partition_list::TopicPartitionList[](https://docs.rs/rdkafka/latest/rdkafka/topic_partition_list/struct.TopicPartitionList.html \"struct rdkafka::topic_partition_list::TopicPartitionList\");`\n\n\n`pub use crate::util::IntoOpaque[](https://docs.rs/rdkafka/latest/rdkafka/util/trait.IntoOpaque.html \"trait rdkafka::util::IntoOpaque\");`\n\n## Modules\u00a7\u27e853\u27e9\n\nadmin\u27e854\u27e9\n    Admin client.\n\nbindings\u27e855\u27e9\n    FFI bindings.\n\nclient\u27e856\u27e9\n    Common client functionality.\n\nconfig\u27e857\u27e9\n    Producer and consumer configuration.\n\nconsumer\u27e858\u27e9\n    Kafka consumers.\n\nerror\u27e859\u27e9\n    Error manipulations.\n\ngroups\u27e860\u27e9\n    Group membership API.\n\nhelpers\u27e861\u27e9\n    Utility functions.\n\nmessage\u27e862\u27e9\n    Store and manipulate Kafka messages.\n\nmetadata\u27e863\u27e9\n    Cluster metadata.\n\nmocking\u27e864\u27e9\n    Mocking functionality\n\nproducer\u27e865\u27e9\n    Kafka producers.\n\nstatistics\u27e866\u27e9\n    Client and broker statistics.\n\ntopic_partition_list\u27e867\u27e9\n    Data structures representing topic, partitions and offsets.\n\ntypes\u27e868\u27e9\n    Aliases for types defined in the auto-generated bindings.\n\nutil\u27e869\u27e9\n    Utility functions and types.\n",
        "references_markdown": "\n\n## References\n\n\u27e81\u27e9 https://docs.rs/rdkafka/latest/settings.html: Settings\n\u27e82\u27e9 https://docs.rs/rdkafka/latest/help.html: Help\n\u27e83\u27e9 https://docs.rs/rdkafka/latest/src/rdkafka/lib.rs.html#1-297: Source\n\u27e84\u27e9 https://github.com/rust-lang/futures-rs: futures\n\u27e85\u27e9 https://kafka.apache.org: Apache Kafka\n\u27e86\u27e9 https://github.com/edenhill/librdkafka: librdkafka\n\u27e87\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#the-library: \u00a7\n\u27e88\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#documentation: \u00a7\n\u27e89\u27e9 https://fede1024.github.io/rust-rdkafka/: Current master branch\n\u27e810\u27e9 https://docs.rs/rdkafka/: Latest release\n\u27e811\u27e9 https://github.com/fede1024/rust-rdkafka/blob/master/changelog.md: Changelog\n\u27e812\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#features: \u00a7\n\u27e813\u27e9 https://github.com/edenhill/librdkafka/blob/master/INTRODUCTION.md#broker-version-compatibility: librdkafka documentation\n\u27e814\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#one-million-messages-per-second: \u00a7\n\u27e815\u27e9 https://docs.rs/rdkafka/*/rdkafka/producer/base_producer/struct.BaseProducer.html: `BaseProducer`\n\u27e816\u27e9 https://github.com/fede1024/kafka-benchmark: kafka-benchmark\n\u27e817\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#client-types: \u00a7\n\u27e818\u27e9 https://docs.rs/rdkafka/*/rdkafka/consumer/base_consumer/struct.BaseConsumer.html: `BaseConsumer`\n\u27e819\u27e9 https://docs.rs/rdkafka/*/rdkafka/producer/base_producer/struct.ThreadedProducer.html: `ThreadedProducer`\n\u27e820\u27e9 https://docs.rs/rdkafka/*/rdkafka/consumer/stream_consumer/struct.StreamConsumer.html: `StreamConsumer`\n\u27e821\u27e9 https://docs.rs/futures/*/futures/stream/trait.Stream.html: `Stream`\n\u27e822\u27e9 https://docs.rs/rdkafka/*/rdkafka/producer/future_producer/struct.FutureProducer.html: `FutureProducer`\n\u27e823\u27e9 https://doc.rust-lang.org/stable/std/future/trait.Future.html: `Future`\n\u27e824\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#asynchronous-data-processing-with-tokio: \u00a7\n\u27e825\u27e9 https://tokio.rs/: Tokio\n\u27e826\u27e9 https://github.com/fede1024/rust-rdkafka/blob/master/examples/asynchronous_processing.rs: asynchronous processing example\n\u27e827\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#at-least-once-delivery: \u00a7\n\u27e828\u27e9 https://github.com/fede1024/rust-rdkafka/blob/master/examples/at_least_once.rs: at-least-once delivery example\n\u27e829\u27e9 https://kafka.apache.org/0101/documentation.html#semantics: message delivery semantics\n\u27e830\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#exactly-once-semantics: \u00a7\n\u27e831\u27e9 https://docs.rs/rdkafka/latest/rdkafka/producer-transactions: Transactions\n\u27e832\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#users: \u00a7\n\u27e833\u27e9 https://github.com/frankmcsherry/timely-dataflow: timely-dataflow\n\u27e834\u27e9 https://github.com/frankmcsherry/blog/blob/master/posts/2017-11-08.md: blog post\n\u27e835\u27e9 https://github.com/fede1024/kafka-view: kafka-view\n\u27e836\u27e9 https://github.com/vertexclique/callysto: callysto\n\u27e837\u27e9 https://github.com/bytewax/bytewax: bytewax\n\u27e838\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#installation: \u00a7\n\u27e839\u27e9 https://github.com/fede1024/rust-rdkafka/tree/master/rdkafka-sys/README.md#features: rdkafka-sys crate\u2019s documentation\n\u27e840\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#minimum-supported-rust-version-msrv: \u00a7\n\u27e841\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#asynchronous-runtimes: \u00a7\n\u27e842\u27e9 https://docs.rs/rdkafka/*/rdkafka/util/trait.AsyncRuntime.html: `AsyncRuntime`\n\u27e843\u27e9 https://github.com/fede1024/rust-rdkafka/blob/master/examples/runtime_smol.rs: smol\n\u27e844\u27e9 https://github.com/fede1024/rust-rdkafka/blob/master/examples/runtime_async_std.rs: async-std\n\u27e845\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#examples: \u00a7\n\u27e846\u27e9 https://github.com/fede1024/rust-rdkafka/blob/master/examples/: `examples`\n\u27e847\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#debugging: \u00a7\n\u27e848\u27e9 https://docs.rs/log: `log`\n\u27e849\u27e9 https://docs.rs/tracing: `tracing`\n\u27e850\u27e9 https://docs.rs/env_logger: `env_logger`\n\u27e851\u27e9 https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md: configuration\n\u27e852\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#reexports: \u00a7\n\u27e853\u27e9 https://docs.rs/rdkafka/latest/rdkafka/#modules: \u00a7\n\u27e854\u27e9 https://docs.rs/rdkafka/latest/rdkafka/admin/index.html: mod rdkafka::admin - admin\n\u27e855\u27e9 https://docs.rs/rdkafka/latest/rdkafka/bindings/index.html: mod rdkafka::bindings - bindings\n\u27e856\u27e9 https://docs.rs/rdkafka/latest/rdkafka/client/index.html: mod rdkafka::client - client\n\u27e857\u27e9 https://docs.rs/rdkafka/latest/rdkafka/config/index.html: mod rdkafka::config - config\n\u27e858\u27e9 https://docs.rs/rdkafka/latest/rdkafka/consumer/index.html: mod rdkafka::consumer - consumer\n\u27e859\u27e9 https://docs.rs/rdkafka/latest/rdkafka/error/index.html: mod rdkafka::error - error\n\u27e860\u27e9 https://docs.rs/rdkafka/latest/rdkafka/groups/index.html: mod rdkafka::groups - groups\n\u27e861\u27e9 https://docs.rs/rdkafka/latest/rdkafka/helpers/index.html: mod rdkafka::helpers - helpers\n\u27e862\u27e9 https://docs.rs/rdkafka/latest/rdkafka/message/index.html: mod rdkafka::message - message\n\u27e863\u27e9 https://docs.rs/rdkafka/latest/rdkafka/metadata/index.html: mod rdkafka::metadata - metadata\n\u27e864\u27e9 https://docs.rs/rdkafka/latest/rdkafka/mocking/index.html: mod rdkafka::mocking - mocking\n\u27e865\u27e9 https://docs.rs/rdkafka/latest/rdkafka/producer/index.html: mod rdkafka::producer - producer\n\u27e866\u27e9 https://docs.rs/rdkafka/latest/rdkafka/statistics/index.html: mod rdkafka::statistics - statistics\n\u27e867\u27e9 https://docs.rs/rdkafka/latest/rdkafka/topic_partition_list/index.html: mod rdkafka::topic_partition_list - topic_partition_list\n\u27e868\u27e9 https://docs.rs/rdkafka/latest/rdkafka/types/index.html: mod rdkafka::types - types\n\u27e869\u27e9 https://docs.rs/rdkafka/latest/rdkafka/util/index.html: mod rdkafka::util - util\n",
        "fit_markdown": "",
        "fit_html": ""
    },
    "downloads": 0,
    "github_stars": 0,
    "dependencies": [],
    "features": {},
    "code_snippets": [],
    "readme_sections": {},
    "librs_downloads": null,
    "source": "crates.io",
    "enhanced_scraping": {},
    "enhanced_features": [],
    "enhanced_dependencies": [],
    "readme_summary": "The `rdkafka` crate is an asynchronous, futures-enabled Apache Kafka client for Rust, built on the high-performance `librdkafka` C library. It supports Kafka versions 0.8.x+, offering features such as message production and consumption (synchronous and asynchronous), automatic consumer rebalancing, customizable offset commits, topic and partition management, access to cluster and group metadata, and exactly-once semantics via transactional producers. It integrates seamlessly with async runtimes like Tokio and provides both low-level and high-level consumer/producer APIs.",
    "feature_summary": null,
    "use_case": "Networking",
    "score": 8.5,
    "factual_counterfactual": "### Pair 1: Asynchronous Capabilities  \n\u2705 Factual: `rdkafka` supports asynchronous message production and consumption via the `FutureProducer` and `StreamConsumer`, which integrate seamlessly with the Tokio runtime.  \n\u274c Counterfactual: `rdkafka` requires the Tokio runtime for all asynchronous operations and cannot function with alternative runtimes like `async-std` or `smol`.  \n\n---\n\n### Pair 2: Kafka Version Compatibility  \n\u2705 Factual: `rdkafka` is compatible with all Kafka versions starting from 0.8.x, and supports advanced features like exactly-once semantics with Kafka brokers version 0.11 and above.  \n\u274c Counterfactual: `rdkafka` is only compatible with Kafka versions 2.0 and above, making it unsuitable for older broker setups.  \n\n---\n\n### Pair 3: Benchmark Performance  \n\u2705 Factual: `rdkafka` can achieve over one million messages per second using the `BaseProducer` in a local Kafka setup with default configurations.  \n\u274c Counterfactual: `rdkafka` achieves one million messages per second only when using the `ThreadedProducer` with a custom Kafka cluster configuration.",
    "source_analysis": null,
    "user_behavior": null,
    "security": null
}