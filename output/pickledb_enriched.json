{
    "name": "pickledb",
    "version": "0.5.1",
    "description": "ALLOW: Positive community sentiment",
    "repository": "",
    "keywords": [],
    "categories": [],
    "readme": {
        "raw_markdown": "[](https://docs.rs/pickledb/latest/pickledb/all.html \"show sidebar\")\n# Crate pickledbCopy item path\n[Settings](https://docs.rs/pickledb/latest/settings.html)\n[Help](https://docs.rs/pickledb/latest/help.html)\nSummary[Source](https://docs.rs/pickledb/latest/src/pickledb/lib.rs.html#1-117)\nExpand description\n## [\u00a7](https://docs.rs/pickledb/latest/pickledb/#pickledb)PickleDB\nPickleDB-rs is a lightweight and simple key-value store written in Rust, heavily inspired by [Python\u2019s PickleDB](https://pythonhosted.org/pickleDB/)\nPickleDB\u2019s architecture is very simple and straight-forward: the whole key-value data structure is stored in memory and is dumped to a file periodically according to a policy defined by the user. There are APIs to create a new key-value store in memory or to load it from a file. Everything runs in the user\u2019s process and memory and in the same thread, which means that the key-value data will be stored in the user process\u2019s memory and each API call will access that key-value store directly and may trigger a dump to the DB file. There are no additional threads or processes created throughout the life-cycle of any of the APIs.\n### [\u00a7](https://docs.rs/pickledb/latest/pickledb/#so-what-is-it-useful-for)So what is it useful for?\nBasically for any use case that needs a simple and relatively small key-value store that can run in-process and be stored in a file. Most of the key-value stores out there provide high scalability, performance and robustness, but in the cost of a very complex architecture, a lot of installation and configuration, and in many cases require a descent amount of resources. But sometimes you don\u2019t need this scalability and performance and all you need is a simple solution that can be easily set up and is easy to use and understand. That\u2019s where PickleDB-rs comes into the picture! I personally encountered several use cases like that and that\u2019s how I came to know about [Python\u2019s PickleDB](https://pythonhosted.org/pickleDB/), and I thought it\u2019d be nice to build one in Rust as well.\n### [\u00a7](https://docs.rs/pickledb/latest/pickledb/#main-features)Main features\nLike the [Python\u2019s PickleDB](https://pythonhosted.org/pickleDB/), the API is very much inspired by Redis API and provides the following main capabilities:\n  * Create a new key-value store in memory or load it from a file\n  * Dump the key-value store to a file according to a user-defined policy\n  * Set and get key-value pairs. A very unique feature in PickleDB is that the key-value map is heterogeneous. Please see more details below\n  * Manage lists. Every list has a name (which is its key in the key-value store) and a list of items it stores. PickleDB provides APIs to create and delete lists and to add or remove items from them. Lists are also heterogeneous, meaning each list can store objects of different types. Please see more details below\n  * Iterate over keys and values in the DB and over items in a list\n\n\nPlease take a look at the API documentation to get more details.\n### [\u00a7](https://docs.rs/pickledb/latest/pickledb/#pickledb-provides-heterogeneous-map-and-lists)PickleDB provides heterogeneous map and lists!\nHeterogeneous data structures are the ones in which the data elements doesn\u2019t belong to the same data type. All the data elements have different data types. As you know, Rust doesn\u2019t have a built-it mechanism for working with heterogeneous data structures. For example: it\u2019s not easy to define a list where each element has a different data type, and it\u2019s also not easy to define a map which contains keys or values of different data types. PickleDB tries to address this challenge and allows values to be of any type and also build lists that contains items of different data types. It achieves that using serialization, which you can read more about below. This is a pretty cool feature that you may find very useful. The different types that are supported are:\n  * All primitive types\n  * Strings\n  * Vectors\n  * Tuples\n  * Structs and Enums that are serializable (please read more below)\n\n\n### [\u00a7](https://docs.rs/pickledb/latest/pickledb/#serialization)Serialization\nSerialization is an important part of PickleDB. It is the way heterogeneous data structures are enabled: instead of saving the actual object, PickleDB stores a serialized version of it. That way all objects are \u201cnormalized\u201d to the same type and can be stored in Rust data structures such as a HashMap or a Vector.\nSerialization is also the way data is stored in a file: before saving to the file, all data in memory is serialized and then it is written to the file; upon loading the serialized data is read from the file and then deserialized to memory. Of course serialization and deserialization has their performance cost but high performance is not one of PickleDB\u2019s main objectives and I think it\u2019s a fair price to pay for achieving heterogeneous data structures.\nIn order to achieve this magic, all objects must be serializable. PickleDB uses the [Serde](https://serde.rs/) library for serialization. Currently 4 types of serialization are supported:\n  * [JSON serialization](https://crates.io/crates/serde_json)\n  * [Bincode serialization](https://crates.io/crates/bincode)\n  * [YAML serialization](https://crates.io/crates/serde_yaml)\n  * [CBOR serialization](https://crates.io/crates/serde_cbor)\n\n\nThe serialization types are enabled and disabled with features (`json` (enabled by default), `bincode`, `yaml`, and `cbor`). To enable them, just add their names to the `features` list when declaring the dependency. To disable JSON, set `default-features` to false. For instance, `pickledb = { version = \"0.5\", features = [\"cbor\", \"yaml\"], default-features = false }` would enable CBOR and YAML only.\nThe user can choose a serialization type to use upon creating a DB or loading it from a file.\nSo what does it mean that all objects must be serializable? That means that all objects that you use must be serializable. Fortunately Serde already provides out-of-the-box serialization for most of the common objects: all primitive types, strings, vectors and tuples are already serializable and you don\u2019t need to do anything to use them. But if you want to define your own structs or enums, you need to make sure they\u2019re serializable, which means that:\n  * They should include the `#[derive(Serialize, Deserialize)]` macro. Please see [here](https://serde.rs/derive.html) for more details\n  * If a struct contains non-primitive members, they should be serializable as well\n  * You should include `serde = \"1.0\"` and `serde_derive = \"1.0\"` dependencies in your `Cargo.toml` file\n\n\nYou can take a look at the examples provided with PickleDB to get a better idea of how this works.\n### [\u00a7](https://docs.rs/pickledb/latest/pickledb/#dumping-data-to-a-file)Dumping data to a file\nAs mentioned before, PickleDB stores all the data in a file for persistency. Dumping data to a file is pretty expensive in terms of time and performance, for various reasons:\n  * Everything in PickleDB runs in the user process context (including file writes), so frequent writes will affect the user process\u2019s performance\n  * The current implementation dumps all of the data into the file, which gets more significant as data gets bigger\n  * Before writing to the file the data is being serialized, which also has a performance cost\n\n\nAlthough performance is not a big concern for PickleDB, I felt it\u2019d make sense to implement different dump policies for the user to choose when creating a new DB or loading one from a file. Here are the different policies and the differences between them:\n  * [PickleDbDumpPolicy::NeverDump](https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.NeverDump) - never dump any change, file will always remain read-only. When choosing this policy even calling to [dump()](https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.dump) won\u2019t dump the data.\n  * [PickleDbDumpPolicy::AutoDump](https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.AutoDump) - every change will be dumped immediately and automatically to the file\n  * [PickleDbDumpPolicy::DumpUponRequest](https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.DumpUponRequest) - data won\u2019t be dumped unless the user calls [dump()](https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.dump) proactively to dump the data\n  * [PickleDbDumpPolicy::PeriodicDump(Duration)](https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.PeriodicDump) - changes will be dumped to the file periodically, no sooner than the Duration provided by the user. The way this mechanism works is as follows: each time there is a DB change the last DB dump time is checked. If the time that has passed since the last dump is higher than Duration, changes will be dumped, otherwise changes will not be dumped.\n\n\nApart from this dump policy, persistency is also kept by a implementing the `Drop` trait for the `PickleDB` object which ensures all in-memory data is dumped to the file upon destruction of the object.\n## Modules[\u00a7](https://docs.rs/pickledb/latest/pickledb/#modules)\n\n[error](https://docs.rs/pickledb/latest/pickledb/error/index.html \"mod pickledb::error\")\n\n## Structs[\u00a7](https://docs.rs/pickledb/latest/pickledb/#structs)\n\n[PickleDb](https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html \"struct pickledb::PickleDb\")\n    A struct that represents a PickleDb object\n\n[PickleDbIterator](https://docs.rs/pickledb/latest/pickledb/struct.PickleDbIterator.html \"struct pickledb::PickleDbIterator\")\n    Iterator object for iterating over keys and values in PickleDB. Returned in [PickleDb::iter()](https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.iter)\n\n[PickleDbIteratorItem](https://docs.rs/pickledb/latest/pickledb/struct.PickleDbIteratorItem.html \"struct pickledb::PickleDbIteratorItem\")\n    The object returned in each iteration when iterating over keys and values in PickleDB\n\n[PickleDbListExtender](https://docs.rs/pickledb/latest/pickledb/struct.PickleDbListExtender.html \"struct pickledb::PickleDbListExtender\")\n    A struct for extending PickleDB lists and adding more items to them\n\n[PickleDbListIterator](https://docs.rs/pickledb/latest/pickledb/struct.PickleDbListIterator.html \"struct pickledb::PickleDbListIterator\")\n    Iterator object for iterating over items in a PickleDB list. Returned in [PickleDb::liter()](https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.liter)\n\n[PickleDbListIteratorItem](https://docs.rs/pickledb/latest/pickledb/struct.PickleDbListIteratorItem.html \"struct pickledb::PickleDbListIteratorItem\")\n    The object returned in each iteration when iterating over a PickleDB list\n## Enums[\u00a7](https://docs.rs/pickledb/latest/pickledb/#enums)\n\n[PickleDbDumpPolicy](https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html \"enum pickledb::PickleDbDumpPolicy\")\n    An enum that determines the policy of dumping PickleDb changes into the file\n\n[SerializationMethod](https://docs.rs/pickledb/latest/pickledb/enum.SerializationMethod.html \"enum pickledb::SerializationMethod\")\n    An enum for specifying the serialization method to use when creating a new PickleDB database or loading one from a file\n",
        "markdown_with_citations": "[](https://docs.rs/pickledb/latest/pickledb/all.html \"show sidebar\")\n# Crate pickledbCopy item path\nSettings\u27e81\u27e9\nHelp\u27e82\u27e9\nSummarySource\u27e83\u27e9\nExpand description\n## \u00a7\u27e84\u27e9PickleDB\nPickleDB-rs is a lightweight and simple key-value store written in Rust, heavily inspired by Python\u2019s PickleDB\u27e85\u27e9\nPickleDB\u2019s architecture is very simple and straight-forward: the whole key-value data structure is stored in memory and is dumped to a file periodically according to a policy defined by the user. There are APIs to create a new key-value store in memory or to load it from a file. Everything runs in the user\u2019s process and memory and in the same thread, which means that the key-value data will be stored in the user process\u2019s memory and each API call will access that key-value store directly and may trigger a dump to the DB file. There are no additional threads or processes created throughout the life-cycle of any of the APIs.\n### \u00a7\u27e86\u27e9So what is it useful for?\nBasically for any use case that needs a simple and relatively small key-value store that can run in-process and be stored in a file. Most of the key-value stores out there provide high scalability, performance and robustness, but in the cost of a very complex architecture, a lot of installation and configuration, and in many cases require a descent amount of resources. But sometimes you don\u2019t need this scalability and performance and all you need is a simple solution that can be easily set up and is easy to use and understand. That\u2019s where PickleDB-rs comes into the picture! I personally encountered several use cases like that and that\u2019s how I came to know about Python\u2019s PickleDB\u27e85\u27e9, and I thought it\u2019d be nice to build one in Rust as well.\n### \u00a7\u27e87\u27e9Main features\nLike the Python\u2019s PickleDB\u27e85\u27e9, the API is very much inspired by Redis API and provides the following main capabilities:\n  * Create a new key-value store in memory or load it from a file\n  * Dump the key-value store to a file according to a user-defined policy\n  * Set and get key-value pairs. A very unique feature in PickleDB is that the key-value map is heterogeneous. Please see more details below\n  * Manage lists. Every list has a name (which is its key in the key-value store) and a list of items it stores. PickleDB provides APIs to create and delete lists and to add or remove items from them. Lists are also heterogeneous, meaning each list can store objects of different types. Please see more details below\n  * Iterate over keys and values in the DB and over items in a list\n\n\nPlease take a look at the API documentation to get more details.\n### \u00a7\u27e88\u27e9PickleDB provides heterogeneous map and lists!\nHeterogeneous data structures are the ones in which the data elements doesn\u2019t belong to the same data type. All the data elements have different data types. As you know, Rust doesn\u2019t have a built-it mechanism for working with heterogeneous data structures. For example: it\u2019s not easy to define a list where each element has a different data type, and it\u2019s also not easy to define a map which contains keys or values of different data types. PickleDB tries to address this challenge and allows values to be of any type and also build lists that contains items of different data types. It achieves that using serialization, which you can read more about below. This is a pretty cool feature that you may find very useful. The different types that are supported are:\n  * All primitive types\n  * Strings\n  * Vectors\n  * Tuples\n  * Structs and Enums that are serializable (please read more below)\n\n\n### \u00a7\u27e89\u27e9Serialization\nSerialization is an important part of PickleDB. It is the way heterogeneous data structures are enabled: instead of saving the actual object, PickleDB stores a serialized version of it. That way all objects are \u201cnormalized\u201d to the same type and can be stored in Rust data structures such as a HashMap or a Vector.\nSerialization is also the way data is stored in a file: before saving to the file, all data in memory is serialized and then it is written to the file; upon loading the serialized data is read from the file and then deserialized to memory. Of course serialization and deserialization has their performance cost but high performance is not one of PickleDB\u2019s main objectives and I think it\u2019s a fair price to pay for achieving heterogeneous data structures.\nIn order to achieve this magic, all objects must be serializable. PickleDB uses the Serde\u27e810\u27e9 library for serialization. Currently 4 types of serialization are supported:\n  * JSON serialization\u27e811\u27e9\n  * Bincode serialization\u27e812\u27e9\n  * YAML serialization\u27e813\u27e9\n  * CBOR serialization\u27e814\u27e9\n\n\nThe serialization types are enabled and disabled with features (`json` (enabled by default), `bincode`, `yaml`, and `cbor`). To enable them, just add their names to the `features` list when declaring the dependency. To disable JSON, set `default-features` to false. For instance, `pickledb = { version = \"0.5\", features = [\"cbor\", \"yaml\"], default-features = false }` would enable CBOR and YAML only.\nThe user can choose a serialization type to use upon creating a DB or loading it from a file.\nSo what does it mean that all objects must be serializable? That means that all objects that you use must be serializable. Fortunately Serde already provides out-of-the-box serialization for most of the common objects: all primitive types, strings, vectors and tuples are already serializable and you don\u2019t need to do anything to use them. But if you want to define your own structs or enums, you need to make sure they\u2019re serializable, which means that:\n  * They should include the `#[derive(Serialize, Deserialize)]` macro. Please see here\u27e815\u27e9 for more details\n  * If a struct contains non-primitive members, they should be serializable as well\n  * You should include `serde = \"1.0\"` and `serde_derive = \"1.0\"` dependencies in your `Cargo.toml` file\n\n\nYou can take a look at the examples provided with PickleDB to get a better idea of how this works.\n### \u00a7\u27e816\u27e9Dumping data to a file\nAs mentioned before, PickleDB stores all the data in a file for persistency. Dumping data to a file is pretty expensive in terms of time and performance, for various reasons:\n  * Everything in PickleDB runs in the user process context (including file writes), so frequent writes will affect the user process\u2019s performance\n  * The current implementation dumps all of the data into the file, which gets more significant as data gets bigger\n  * Before writing to the file the data is being serialized, which also has a performance cost\n\n\nAlthough performance is not a big concern for PickleDB, I felt it\u2019d make sense to implement different dump policies for the user to choose when creating a new DB or loading one from a file. Here are the different policies and the differences between them:\n  * PickleDbDumpPolicy::NeverDump\u27e817\u27e9 - never dump any change, file will always remain read-only. When choosing this policy even calling to dump()\u27e818\u27e9 won\u2019t dump the data.\n  * PickleDbDumpPolicy::AutoDump\u27e819\u27e9 - every change will be dumped immediately and automatically to the file\n  * PickleDbDumpPolicy::DumpUponRequest\u27e820\u27e9 - data won\u2019t be dumped unless the user calls dump()\u27e818\u27e9 proactively to dump the data\n  * PickleDbDumpPolicy::PeriodicDump(Duration)\u27e821\u27e9 - changes will be dumped to the file periodically, no sooner than the Duration provided by the user. The way this mechanism works is as follows: each time there is a DB change the last DB dump time is checked. If the time that has passed since the last dump is higher than Duration, changes will be dumped, otherwise changes will not be dumped.\n\n\nApart from this dump policy, persistency is also kept by a implementing the `Drop` trait for the `PickleDB` object which ensures all in-memory data is dumped to the file upon destruction of the object.\n## Modules\u00a7\u27e822\u27e9\n\nerror\u27e823\u27e9\n\n## Structs\u00a7\u27e824\u27e9\n\nPickleDb\u27e825\u27e9\n    A struct that represents a PickleDb object\n\nPickleDbIterator\u27e826\u27e9\n    Iterator object for iterating over keys and values in PickleDB. Returned in PickleDb::iter()\u27e827\u27e9\n\nPickleDbIteratorItem\u27e828\u27e9\n    The object returned in each iteration when iterating over keys and values in PickleDB\n\nPickleDbListExtender\u27e829\u27e9\n    A struct for extending PickleDB lists and adding more items to them\n\nPickleDbListIterator\u27e830\u27e9\n    Iterator object for iterating over items in a PickleDB list. Returned in PickleDb::liter()\u27e831\u27e9\n\nPickleDbListIteratorItem\u27e832\u27e9\n    The object returned in each iteration when iterating over a PickleDB list\n## Enums\u00a7\u27e833\u27e9\n\nPickleDbDumpPolicy\u27e834\u27e9\n    An enum that determines the policy of dumping PickleDb changes into the file\n\nSerializationMethod\u27e835\u27e9\n    An enum for specifying the serialization method to use when creating a new PickleDB database or loading one from a file\n",
        "references_markdown": "\n\n## References\n\n\u27e81\u27e9 https://docs.rs/pickledb/latest/settings.html: Settings\n\u27e82\u27e9 https://docs.rs/pickledb/latest/help.html: Help\n\u27e83\u27e9 https://docs.rs/pickledb/latest/src/pickledb/lib.rs.html#1-117: Source\n\u27e84\u27e9 https://docs.rs/pickledb/latest/pickledb/#pickledb: \u00a7\n\u27e85\u27e9 https://pythonhosted.org/pickleDB/: Python\u2019s PickleDB\n\u27e86\u27e9 https://docs.rs/pickledb/latest/pickledb/#so-what-is-it-useful-for: \u00a7\n\u27e87\u27e9 https://docs.rs/pickledb/latest/pickledb/#main-features: \u00a7\n\u27e88\u27e9 https://docs.rs/pickledb/latest/pickledb/#pickledb-provides-heterogeneous-map-and-lists: \u00a7\n\u27e89\u27e9 https://docs.rs/pickledb/latest/pickledb/#serialization: \u00a7\n\u27e810\u27e9 https://serde.rs/: Serde\n\u27e811\u27e9 https://crates.io/crates/serde_json: JSON serialization\n\u27e812\u27e9 https://crates.io/crates/bincode: Bincode serialization\n\u27e813\u27e9 https://crates.io/crates/serde_yaml: YAML serialization\n\u27e814\u27e9 https://crates.io/crates/serde_cbor: CBOR serialization\n\u27e815\u27e9 https://serde.rs/derive.html: here\n\u27e816\u27e9 https://docs.rs/pickledb/latest/pickledb/#dumping-data-to-a-file: \u00a7\n\u27e817\u27e9 https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.NeverDump: PickleDbDumpPolicy::NeverDump\n\u27e818\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.dump: dump()\n\u27e819\u27e9 https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.AutoDump: PickleDbDumpPolicy::AutoDump\n\u27e820\u27e9 https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.DumpUponRequest: PickleDbDumpPolicy::DumpUponRequest\n\u27e821\u27e9 https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html#variant.PeriodicDump: PickleDbDumpPolicy::PeriodicDump(Duration)\n\u27e822\u27e9 https://docs.rs/pickledb/latest/pickledb/#modules: \u00a7\n\u27e823\u27e9 https://docs.rs/pickledb/latest/pickledb/error/index.html: mod pickledb::error - error\n\u27e824\u27e9 https://docs.rs/pickledb/latest/pickledb/#structs: \u00a7\n\u27e825\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html: struct pickledb::PickleDb - PickleDb\n\u27e826\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDbIterator.html: struct pickledb::PickleDbIterator - PickleDbIterator\n\u27e827\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.iter: PickleDb::iter()\n\u27e828\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDbIteratorItem.html: struct pickledb::PickleDbIteratorItem - PickleDbIteratorItem\n\u27e829\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDbListExtender.html: struct pickledb::PickleDbListExtender - PickleDbListExtender\n\u27e830\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDbListIterator.html: struct pickledb::PickleDbListIterator - PickleDbListIterator\n\u27e831\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDb.html#method.liter: PickleDb::liter()\n\u27e832\u27e9 https://docs.rs/pickledb/latest/pickledb/struct.PickleDbListIteratorItem.html: struct pickledb::PickleDbListIteratorItem - PickleDbListIteratorItem\n\u27e833\u27e9 https://docs.rs/pickledb/latest/pickledb/#enums: \u00a7\n\u27e834\u27e9 https://docs.rs/pickledb/latest/pickledb/enum.PickleDbDumpPolicy.html: enum pickledb::PickleDbDumpPolicy - PickleDbDumpPolicy\n\u27e835\u27e9 https://docs.rs/pickledb/latest/pickledb/enum.SerializationMethod.html: enum pickledb::SerializationMethod - SerializationMethod\n",
        "fit_markdown": "",
        "fit_html": ""
    },
    "downloads": 0,
    "github_stars": 0,
    "dependencies": [],
    "features": {},
    "code_snippets": [],
    "readme_sections": {},
    "librs_downloads": null,
    "source": "crates.io",
    "enhanced_scraping": {},
    "enhanced_features": [],
    "enhanced_dependencies": [],
    "readme_summary": "The `pickledb` crate is a lightweight, in-process key-value store inspired by Python's PickleDB, designed for simplicity and ease of use. It supports heterogeneous data structures (maps and lists with mixed data types) via Serde-based serialization, with options for JSON, Bincode, YAML, or CBOR formats. Key features include customizable data persistence policies, list management, and iteration over keys, values, and list items.",
    "feature_summary": null,
    "use_case": "Database",
    "score": 5.0,
    "factual_counterfactual": "### Pair 1: Serialization Support  \n\u2705 **Factual**: PickleDB uses the Serde library for serialization and supports multiple formats, including JSON, Bincode, YAML, and CBOR, which can be enabled or disabled via Cargo features.  \n\u274c **Counterfactual**: PickleDB only supports JSON serialization and does not allow users to choose other formats like Bincode or YAML.  \n\n---\n\n### Pair 2: Heterogeneous Data Structures  \n\u2705 **Factual**: PickleDB allows the creation of heterogeneous maps and lists, enabling storage of values with different data types, such as primitives, strings, vectors, tuples, and serializable structs or enums.  \n\u274c **Counterfactual**: PickleDB requires all keys and values in maps and lists to have the same data type, as heterogeneous data structures are not supported.  \n\n---\n\n### Pair 3: Dumping Policies  \n\u2705 **Factual**: PickleDB supports multiple dump policies, including `AutoDump`, `DumpUponRequest`, `PeriodicDump`, and `NeverDump`, allowing users to control how and when data is persisted to a file.  \n\u274c **Counterfactual**: PickleDB automatically dumps all changes to a file after every API call, and users cannot configure or disable this behavior.",
    "source_analysis": null,
    "user_behavior": null,
    "security": null
}